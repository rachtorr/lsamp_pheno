---
title: "pheno"
author: "rachel torres"
date: "2025-01-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# if running this for the first time, you'll need to uncomment the lines 13-16 and run those, otherwise will get error trying to load phenocamr

#install.packages("devtools")
#if(!require(remotes)){install.packages("remotes")}
#remotes::install_github("bluegreen-labs/phenor@v1.3.1")
#install.packages("phenocamr")

library(phenor)
library(phenocamr)
library(tidyverse)
library(tsibble)
library(fable)
library(fabletools)
```

## tutorial - NEON pheno packages 

https://www.neonscience.org/resources/learning-hub/tutorials/phenocam-phenor-modeling

For the latest version, install `phenor` from here: https://github.com/bluegreen-labs/phenor (be sure to update all packages for installation to work, and install GenSA)

See a map of phenocam sites [here](https://phenocam.nau.edu/webcam/network/map/)

This example will look at the NEON site GRSM Great Smoky Mountains 


```{r download}

# change my_site to the phenocam site you are looking at 
my_site = "NEON.D17.SOAP.DP1.00033"

#my_site_under = "NEON.D17.SOAP.DP1.00042"

# can see rois to select where to download(regions of interest)
list_rois() %>% 
  filter(site==my_site)
# roi id 1000 has been around the longest with least amount of missing data, makese sense to use as example 

# download phenocam - this should create 2 csv files 
phenocamr::download_phenocam(
  veg_type = "EN", #DB for decid broadleaf, EN for evergreen, default is ALL
  roi_id = 1000,
  site = my_site,
  phenophase = TRUE,
  out_dir = "." # saves in current working dir
  )


```

A new file should be downloaded in your folder, the format is: `Site_ID_Veg_ROI_3day.csv` or with `_transition.csv`. For the example above, the files start with `NEON.D077.GRSM.DP1.00033_DB_1000_3day`

The data is set up as a `phenocamr` type, which includes a list with metadata and timeseries data

## following steps from phenocamr vignette 

[see website here](https://bluegreen-labs.github.io/phenocamr/articles/phenocamr-vignette.html)

source has clear steps, but uses base plotting, below I create same plot with ggplot. In this plot, the green line represents date when green up has reached 50%, and the red line represents date when 50% of gcc was lost. To see how this is calculated, check out the figures on page 6 of the [phenocam access guide](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://phenocam.nau.edu/education/PhenoCam_Access_Guide.pdf).

```{r phenocamr}
# read as phenocamr type 
df = read_phenocam(paste(my_site,"EN_1000_3day.csv", sep="_"))

df <- expand_phenocam(df) # expand every 3 day to every day 

df <- detect_outliers(df) # detect outliers

df <- smooth_ts(df) # smooth data using AIC 

phenology_dates <- phenophases(df, internal = TRUE) # calculate rising and falling

as.data.frame(df$data) %>% 
  mutate(date = as.Date(date)) %>% 
  ggplot(aes(x=date, y=smooth_gcc_90)) + 
  geom_line() +
  labs(x="Date", y="GCC") + 
  # rising "spring" greenup dates 
  geom_vline(data=phenology_dates$rising, aes(xintercept=transition_50), col="green") + 
  # falling 'autumn' senescence dates 
  geom_vline(data=phenology_dates$falling, aes(xintercept=transition_50), col="brown")

```


# explore data and make plots 

Find the metadata here:
https://phenocam.nau.edu/webcam/tools/summary_file_format/

## transition days 

```{r transition, eval=T}
# alternative to the above section that used the phenophases function 
# load in transition days 
dft = read_phenocam(paste(my_site,"EN_1000_3day_transition_dates.csv", sep="_"))$data

names(dft)

# get rising and falling dates 
td <- dft %>% 
  dplyr::filter(direction=="rising" & gcc_value=="gcc_90")

fd <- dft %>% 
  dplyr::filter(direction=="falling" & gcc_value=="gcc_90")

# can also compare different years on same axis 
# get day of year for transition dates 
td_doy = td %>% 
  mutate(doy_t50 = yday(transition_50),
         year = year(transition_50)) 

ggplot(df$data, aes(x=doy, y=smooth_gcc_90, col=as.factor(year))) +
  geom_line() +
  geom_vline(data=td_doy, aes(xintercept=doy_t50, col=as.factor(year)), linetype="dashed")

# this is not a great visualization, hard to see, can try to zoom in 
df$data %>% filter(doy<150) %>% 
  ggplot(aes(x=doy, y=smooth_gcc_90, col=as.factor(year))) +
  geom_line() +
  geom_vline(data=td_doy, aes(xintercept=doy_t50, col=as.factor(year)), linetype="dashed")


# can also use transition points in a scatter plot 
td_doy %>% 
  ggplot(aes(x=as.factor(year), y=doy_t50)) +
  geom_point(aes(col=threshold_50)) 

```


## climate data: Daymet  

Use the function `merge_daymet()` to get climate and daylength

Daymet is continuous, gridded estimates of weather and climate variables creted through statistical interpolation of ground based measurements. Read more here: https://daymet.ornl.gov/

```{r daymet}
site_clim = merge_daymet(paste(my_site, "EN_1000_3day.csv", sep="_"))

names(site_clim)

site_data = site_clim$data

# plot daily rainfall and temperatures 
ggplot(site_data, aes(x=date, y=prcp..mm.day.))+
  geom_line() + 
  labs(y="precip [mm]", title="Daily Precipitation") +
  theme_bw() 

ggplot(site_data) +
  geom_point(aes(x=date, y=tmax..deg.c., col="tmax"), col="red") +
  geom_point(aes(x=date, y=tmin..deg.c., col="tmin"), col="blue") +
  labs(y="temp. deg C", title = "Daily temperature") +
  theme_bw()

```

## Explore data with climate 

In this example, looking at how daily values might be related to climate data. If using transition dates, would want to look at the dataframe `td_doy` and would need a climate data frame summarized be annual values to join them. More to come soon! 

```{r explore_clim}

# day of the year patterns 
ggplot(site_data) +
  geom_point(aes(x=doy, y=gcc_90))

# precipitation
ggplot(site_data) + 
  geom_point(aes(x=prcp..mm.day., y=gcc_90, col=doy)) + scale_color_viridis_c()

# day of the year with daylength 
ggplot(site_data) + 
   geom_point(aes(x=doy, y=gcc_90, col=dayl..s.)) + scale_color_viridis_c()

# daylength 
ggplot(site_data) +
  geom_point(aes(x=dayl..s., y=gcc_90)) 

# min temperatures 
ggplot(site_data) +
  geom_point(aes(x=tmin..deg.c., y=gcc_90))
# max temperatures 
ggplot(site_data) +
  geom_point(aes(x=tmax..deg.c., y=gcc_90))

```

## start with time series linear model 

Forecasting daily values 

```{r lm}

# subset data 
data_mod = site_data %>% dplyr::filter(year<2020)

# start with trying 1-2 variables 
lm_test = as_tsibble(data_mod) %>% 
  fabletools::model(lm1=fable::TSLM(gcc_90~dayl..s.),
        lm2 = fable::TSLM(gcc_90~dayl..s.+tmin..deg.c.))

# see residuals, p-vals, Rsquares, etc. 
report(lm_test)

# predict with remaining years
data_pred = site_data %>% 
  dplyr::filter(year>=2020) %>% 
  select(gcc_90, dayl..s., tmin..deg.c., year, doy, date) 

# predict using fabletools::forecast function - note data must be tsibble 
fc_lm <- lm_test %>% 
  fabletools::forecast(
    new_data=data_pred %>% 
      as_tsibble(index=date)
  )
# note that output contains distribution of gcc_90 and the mean values 

# plot model 
ggplot(fc_lm) + 
  geom_point(aes(x=date, y=.mean, col=.model)) + 
  geom_point(data=data_pred, aes(x=date, y=gcc_90, col="obs")) 

# based on report and visual, model with 2 variables does better 

# we can also compare to obs. with modeled 
data_pred %>% 
  rename(obs = gcc_90) %>% 
  inner_join(fc_lm, by='date') %>% 
  filter(.model=="lm2") %>% 
  ggplot() + geom_point(aes(x=obs, y=.mean), alpha=0.5) +
  geom_abline(aes(slope=1, intercept=0))


```

## Load in Snow Water Equivalent Phenology

Use `full_join()` to combine with GCC phenology. 


```{r snow}

snow <- read.csv("TMR_snotel_pheno.csv")

# join with transition dates of spring gcc 

td$year = year(td$transition_50)
td$gcc_yday50 = yday(td$transition_50) # make column for day of year

snow_gcc_join <- full_join(snow, td, by="year")

head(snow_gcc_join)

# plot 
ggplot(snow_gcc_join, aes(x=max_swe, y=max_gcc)) + geom_point()

ggplot(snow_gcc_join, aes(x=max_swe_doy, y=gcc_yday50)) + geom_point() +
  facet_grid('year')




```
